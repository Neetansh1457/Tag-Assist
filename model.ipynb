{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:14:24.257209Z",
     "start_time": "2026-02-15T08:14:23.967327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_core_data_strong_text(n_samples=20000):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "\n",
    "        # Behavioral Risk\n",
    "        BR = np.random.beta(4, 4)\n",
    "\n",
    "        order_velocity = max(np.random.normal(BR * 10, 1.2), 0)\n",
    "        device_changes_7d = np.random.poisson(BR * 3)\n",
    "        ip_changes_7d = np.random.poisson(BR * 2)\n",
    "        unpaid_ratio = min(np.random.beta(2 + BR*3, 5), 1)\n",
    "        risky_category_flag = np.random.binomial(1, BR * 0.7)\n",
    "\n",
    "        # Reasoning Quality\n",
    "        RQ = np.random.beta(3, 3)\n",
    "\n",
    "        # Context Intelligence Signal (binary)\n",
    "        CIS = np.random.binomial(1, BR * 0.7)\n",
    "\n",
    "        # Approval Logic (Text now stronger)\n",
    "        approval_score = (\n",
    "            0.50 * BR +\n",
    "            0.20 * RQ +\n",
    "            0.30 * CIS +\n",
    "            np.random.normal(0, 0.03)\n",
    "        )\n",
    "\n",
    "        approval_score = min(max(approval_score, 0), 1)\n",
    "        approved = np.random.binomial(1, approval_score)\n",
    "\n",
    "        rows.append([\n",
    "            order_velocity,\n",
    "            device_changes_7d,\n",
    "            ip_changes_7d,\n",
    "            unpaid_ratio,\n",
    "            risky_category_flag,\n",
    "            BR,\n",
    "            RQ,\n",
    "            CIS,\n",
    "            approved\n",
    "        ])\n",
    "\n",
    "    columns = [\n",
    "        \"order_velocity\",\n",
    "        \"device_changes_7d\",\n",
    "        \"ip_changes_7d\",\n",
    "        \"unpaid_ratio\",\n",
    "        \"risky_category_flag\",\n",
    "        \"BR\",\n",
    "        \"RQ\",\n",
    "        \"CIS\",\n",
    "        \"approved\"\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(rows, columns=columns)\n"
   ],
   "id": "bf1c9efbdc6b9bcb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:14:28.570397Z",
     "start_time": "2026-02-15T08:14:28.565485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_powerful_annotations(df):\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        behavior_section = []\n",
    "\n",
    "        if row[\"order_velocity\"] > 6:\n",
    "            behavior_section.append(\n",
    "                \"The account exhibits a significant spike in transaction velocity compared to its historical baseline.\"\n",
    "            )\n",
    "\n",
    "        if row[\"device_changes_7d\"] > 1:\n",
    "            behavior_section.append(\n",
    "                \"Multiple new devices were introduced within a short timeframe, indicating possible account instability.\"\n",
    "            )\n",
    "\n",
    "        if row[\"ip_changes_7d\"] > 1:\n",
    "            behavior_section.append(\n",
    "                \"Rapid IP address rotation suggests potential proxy or anonymized access patterns.\"\n",
    "            )\n",
    "\n",
    "        if row[\"unpaid_ratio\"] > 0.4:\n",
    "            behavior_section.append(\n",
    "                \"A high proportion of unpaid transactions raises concern for coordinated misuse.\"\n",
    "            )\n",
    "\n",
    "        if row[\"risky_category_flag\"] == 1:\n",
    "            behavior_section.append(\n",
    "                \"Order composition includes high-risk merchandise categories frequently targeted in abuse cases.\"\n",
    "            )\n",
    "\n",
    "        context_section = \"\"\n",
    "        if row[\"CIS\"] == 1:\n",
    "            context_section = (\n",
    "                \"Additionally, internal investigation notes indicate linkage to previously confirmed fraud clusters \"\n",
    "                \"based on device fingerprint similarity and synchronized ordering behavior across related accounts.\"\n",
    "            )\n",
    "\n",
    "        # Reasoning tone variation\n",
    "        if row[\"RQ\"] > 0.7:\n",
    "            tone = (\n",
    "                \"Based on the cumulative behavioral and contextual evidence, escalation to fraud classification \"\n",
    "                \"is strongly justified.\"\n",
    "            )\n",
    "        elif row[\"RQ\"] > 0.4:\n",
    "            tone = (\n",
    "                \"The observed indicators collectively suggest elevated fraud risk warranting tag approval.\"\n",
    "            )\n",
    "        else:\n",
    "            tone = (\n",
    "                \"While suspicious elements are present, evidence strength remains moderate and should be interpreted cautiously.\"\n",
    "            )\n",
    "\n",
    "        full_annotation = \" \".join(behavior_section) + \" \" + context_section + \" \" + tone\n",
    "\n",
    "        annotations.append(full_annotation.strip())\n",
    "\n",
    "    df[\"annotation_text\"] = annotations\n",
    "    return df\n"
   ],
   "id": "96cde35389f6eff9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:14:39.359933Z",
     "start_time": "2026-02-15T08:14:38.839662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_core_strong = generate_core_data_strong_text(20000)\n",
    "df_strong = add_powerful_annotations(df_core_strong.copy())\n",
    "\n",
    "df_model = df_strong.drop(columns=[\"BR\", \"RQ\", \"CIS\"])\n",
    "print(\"Approval rate:\", df_model[\"approved\"].mean())\n"
   ],
   "id": "98899bbb84c6e44f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval rate: 0.4551\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:17:07.148363Z",
     "start_time": "2026-02-15T08:17:05.834407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Structured only\n",
    "X_behavior = df_strong.drop(columns=[\"annotation_text\", \"approved\", \"BR\", \"RQ\", \"CIS\"])\n",
    "y = df_strong[\"approved\"]\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_behavior,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "behavior_model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "behavior_model.fit(X_train_b, y_train_b)\n",
    "\n",
    "y_prob_behavior = behavior_model.predict_proba(X_test_b)[:, 1]\n",
    "\n",
    "roc_behavior = roc_auc_score(y_test_b, y_prob_behavior)\n",
    "\n",
    "print(\"Behavioral Model ROC:\", roc_behavior)\n"
   ],
   "id": "64635b57184ea017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavioral Model ROC: 0.5943672802180082\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:18:39.402086Z",
     "start_time": "2026-02-15T08:17:09.858990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model_embed = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model_embed.encode(\n",
    "    df_strong[\"annotation_text\"].tolist(),\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "X_text = embeddings\n",
    "\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    X_text,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "text_model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "text_model.fit(X_train_t, y_train_t)\n",
    "\n",
    "y_prob_text = text_model.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "roc_text = roc_auc_score(y_test_t, y_prob_text)\n",
    "\n",
    "print(\"Text Model ROC:\", roc_text)\n"
   ],
   "id": "3ad4c914237203e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shree\\PycharmProjects\\InvoiceGenerator\\TagAssist\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1288.78it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001B[1mBertModel LOAD REPORT\u001B[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n",
      "Batches: 100%|██████████| 625/625 [01:15<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Model ROC: 0.6763892080269608\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:18:41.253264Z",
     "start_time": "2026-02-15T08:18:41.249145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_score = 0.6 * y_prob_behavior + 0.4 * y_prob_text\n",
    "\n",
    "roc_final = roc_auc_score(y_test_b, final_score)\n",
    "\n",
    "print(\"Final Combined ROC:\", roc_final)\n"
   ],
   "id": "c0a3252c4b7865a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Combined ROC: 0.6692732268688726\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:19:47.564306Z",
     "start_time": "2026-02-15T08:19:47.536471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best_roc = 0\n",
    "best_alpha = 0\n",
    "\n",
    "for alpha in np.arange(0, 1.01, 0.05):\n",
    "    combined = alpha * y_prob_behavior + (1 - alpha) * y_prob_text\n",
    "    roc = roc_auc_score(y_test_b, combined)\n",
    "\n",
    "    if roc > best_roc:\n",
    "        best_roc = roc\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(\"Best Alpha (behavior weight):\", best_alpha)\n",
    "print(\"Best Combined ROC:\", best_roc)\n"
   ],
   "id": "fa2b63ce903c079d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha (behavior weight): 0.30000000000000004\n",
      "Best Combined ROC: 0.6826489333397832\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T08:21:11.644927Z",
     "start_time": "2026-02-15T08:21:11.484149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(behavior_model, \"behavior_model.pkl\")\n",
    "joblib.dump(text_model, \"text_model.pkl\")\n",
    "joblib.dump(model_embed, \"embedding_model.pkl\")\n"
   ],
   "id": "5eb3cb3e7298b286",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84ba94d922d12dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
