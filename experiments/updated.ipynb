{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:07:33.042079Z",
     "start_time": "2026-02-15T07:07:33.040074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ],
   "id": "cd25db8b82e33796",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-15T07:07:33.072392Z",
     "start_time": "2026-02-15T07:07:33.067494Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_synthetic_data(n_samples=20000):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "\n",
    "        # ---- Latent Fraud Intensity (skewed mostly low) ----\n",
    "        true_fraud_intensity = np.random.beta(4, 4)  # mostly low, some medium, few high\n",
    "\n",
    "        # ---- Structured Features Derived From Latent Fraud ----\n",
    "\n",
    "        order_velocity = np.random.normal(\n",
    "            loc=true_fraud_intensity * 10,\n",
    "            scale=1.5\n",
    "        )\n",
    "\n",
    "        card_velocity = np.random.normal(\n",
    "            loc=true_fraud_intensity * 8,\n",
    "            scale=1.2\n",
    "        )\n",
    "\n",
    "        risky_pattern_flag = np.random.binomial(\n",
    "            1, true_fraud_intensity * 0.8\n",
    "        )\n",
    "\n",
    "        bad_gsi_flag = np.random.binomial(\n",
    "            1, true_fraud_intensity * 0.7\n",
    "        )\n",
    "\n",
    "        unpaid_orders = np.random.poisson(\n",
    "            lam=true_fraud_intensity * 3\n",
    "        )\n",
    "\n",
    "        prior_disputes = np.random.poisson(\n",
    "            lam=true_fraud_intensity * 4\n",
    "        )\n",
    "\n",
    "        account_age_days = np.random.exponential(\n",
    "            scale=400 * (1 - true_fraud_intensity + 0.1)\n",
    "        )\n",
    "\n",
    "        linked_accounts_count = np.random.poisson(\n",
    "            lam=true_fraud_intensity * 2\n",
    "        )\n",
    "\n",
    "        # Ensure no negatives from normal distributions\n",
    "        order_velocity = max(order_velocity, 0)\n",
    "        card_velocity = max(card_velocity, 0)\n",
    "\n",
    "        # ---- Annotation Derived From Signals ----\n",
    "        annotation_parts = []\n",
    "\n",
    "        if order_velocity > 6:\n",
    "            annotation_parts.append(\"High order velocity observed.\")\n",
    "\n",
    "        if card_velocity > 5:\n",
    "            annotation_parts.append(\"Card velocity spike detected.\")\n",
    "\n",
    "        if risky_pattern_flag:\n",
    "            annotation_parts.append(\"Risky ordering pattern consistent with abuse.\")\n",
    "\n",
    "        if bad_gsi_flag:\n",
    "            annotation_parts.append(\"Browser/timezone anomaly and recent password change.\")\n",
    "\n",
    "        if unpaid_orders > 1:\n",
    "            annotation_parts.append(\"Multiple unpaid orders linked to account.\")\n",
    "\n",
    "        if not annotation_parts:\n",
    "            annotation_parts.append(\"No strong fraud indicators identified.\")\n",
    "\n",
    "        annotation_text = \" \".join(annotation_parts)\n",
    "\n",
    "        # ---- Approval Logic (Investigator 90% Correct) ----\n",
    "        approval_prob = true_fraud_intensity * 0.9 + np.random.normal(0, 0.05)\n",
    "        approval_prob = min(max(approval_prob, 0), 1)\n",
    "\n",
    "        approved = np.random.binomial(1, approval_prob)\n",
    "\n",
    "        data.append([\n",
    "            order_velocity,\n",
    "            card_velocity,\n",
    "            risky_pattern_flag,\n",
    "            bad_gsi_flag,\n",
    "            unpaid_orders,\n",
    "            prior_disputes,\n",
    "            account_age_days,\n",
    "            linked_accounts_count,\n",
    "            annotation_text,\n",
    "            approved\n",
    "        ])\n",
    "\n",
    "    columns = [\n",
    "        \"order_velocity\",\n",
    "        \"card_velocity\",\n",
    "        \"risky_pattern_flag\",\n",
    "        \"bad_gsi_flag\",\n",
    "        \"unpaid_orders\",\n",
    "        \"prior_disputes\",\n",
    "        \"account_age_days\",\n",
    "        \"linked_accounts_count\",\n",
    "        \"annotation_text\",\n",
    "        \"approved\"\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(data, columns=columns)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:07:57.218083Z",
     "start_time": "2026-02-15T07:07:57.063891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mixed = generate_synthetic_data(20000)\n",
    "\n",
    "print(\"Mixed Approval Rate:\", df_mixed[\"approved\"].mean())"
   ],
   "id": "44abcb5a5d8fa394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Approval Rate: 0.4537\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:08:19.561780Z",
     "start_time": "2026-02-15T07:08:19.553510Z"
    }
   },
   "cell_type": "code",
   "source": "df_mixed[\"approved\"].value_counts(normalize=True)\n",
   "id": "1ae0f3d07e20102b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approved\n",
       "0    0.5463\n",
       "1    0.4537\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:08:39.936964Z",
     "start_time": "2026-02-15T07:08:39.927940Z"
    }
   },
   "cell_type": "code",
   "source": "df_mixed.corr(numeric_only=True)[\"approved\"].sort_values(ascending=False)\n",
   "id": "d3c060141f5082d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approved                 1.000000\n",
       "order_velocity           0.234553\n",
       "card_velocity            0.229069\n",
       "prior_disputes           0.131230\n",
       "unpaid_orders            0.115761\n",
       "linked_accounts_count    0.115555\n",
       "bad_gsi_flag             0.085675\n",
       "risky_pattern_flag       0.077181\n",
       "account_age_days        -0.077668\n",
       "Name: approved, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGBoost\n",
   "id": "e7e56db6f79d69d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:13:50.561921Z",
     "start_time": "2026-02-15T07:13:46.094787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Features (NO annotation_text)\n",
    "X = df_mixed.drop(columns=[\"annotation_text\", \"approved\"])\n",
    "y = df_mixed[\"approved\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"Structured-only XGBoost ROC-AUC:\", roc)\n"
   ],
   "id": "3ca4705c4ad71162",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured-only XGBoost ROC-AUC: 0.6506341638954193\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:21:20.734008Z",
     "start_time": "2026-02-15T07:20:24.282238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_embed = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model_embed.encode(\n",
    "    df_mixed[\"annotation_text\"].tolist(),\n",
    "    show_progress_bar=True\n",
    ")\n"
   ],
   "id": "d997ba1beff31325",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shree\\PycharmProjects\\InvoiceGenerator\\TagAssist\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Shree\\PycharmProjects\\InvoiceGenerator\\TagAssist\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shree\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1078.39it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001B[1mBertModel LOAD REPORT\u001B[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001B[0m\n",
      "Batches: 100%|██████████| 625/625 [00:23<00:00, 26.69it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:21:45.430248Z",
     "start_time": "2026-02-15T07:21:45.415011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "X_struct = df_mixed.drop(columns=[\"annotation_text\", \"approved\"]).values\n",
    "\n",
    "X_combined = np.hstack([X_struct, embeddings])\n",
    "y = df_mixed[\"approved\"].values\n"
   ],
   "id": "2982f81c2834192b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:21:52.121881Z",
     "start_time": "2026-02-15T07:21:52.118979Z"
    }
   },
   "cell_type": "code",
   "source": "embeddings.shape\n",
   "id": "e6299276e3d586c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:22:17.293726Z",
     "start_time": "2026-02-15T07:22:17.275614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Structured features only\n",
    "X_struct = df_mixed.drop(columns=[\"annotation_text\", \"approved\"]).values\n",
    "\n",
    "# Combine structured + embeddings\n",
    "X_combined = np.hstack([X_struct, embeddings])\n",
    "\n",
    "y = df_mixed[\"approved\"].values\n"
   ],
   "id": "7c1060d1a1620a8b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T07:22:24.711261Z",
     "start_time": "2026-02-15T07:22:23.276421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "xgb_combined = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_combined.fit(X_train, y_train)\n",
    "\n",
    "y_prob_combined = xgb_combined.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_combined = roc_auc_score(y_test, y_prob_combined)\n",
    "\n",
    "print(\"Structured + Embeddings XGBoost ROC-AUC:\", roc_combined)\n"
   ],
   "id": "7993220394be97d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured + Embeddings XGBoost ROC-AUC: 0.6278704741370559\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ba4e5e54243a2de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
